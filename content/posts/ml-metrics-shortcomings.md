---
title: "MIT研究：机器学习指标的陷阱——为何平均指标可能掩盖问题"
date: 2026-01-31
draft: false
description: "MIT研究人员发现机器学习模型在应用于新环境时可能失效"
coverImage: "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&q=80"
tags: ["AI", "Machine Learning", "MIT", "Research"]
categories: ["AI"]
---

MIT研究人员发现，当模型应用于训练数据以外的场景时，会出现显著的模型失效情况，这对在新环境中部署模型时进行测试提出了质疑。

## 发现的问题

"我们证明，即使你在大量数据上训练模型并选择最佳平均模型，在新环境中，这个'最佳模型'可能是6-75%新数据中最差的模型，"MIT的Marzyeh Ghassemi副教授说。

例如，在一家医院有效诊断胸部X光片中的疾病的模型可能在另一家医院被认定为有效，但研究人员的表现评估显示，一些表现最佳的模型在第二家医院多达75%的患者中表现最差，即使该医院整体平均性能很高。

## 虚假相关性问题

研究指出了虚假相关的问题——即ML系统由于训练数据中的偏见而做出错误预测。在医学诊断模型中，模型可能学会了将特定标记与某种病理相关联，而在没有该标记的另一家医院，那种病理可能会被遗漏。

"我们希望模型学习查看患者的解剖特征然后做出决定，"论文第一作者Olawale Salaudeen说。"但实际上，数据中与决策相关的任何东西都可能被模型使用。这些相关可能不会随着环境变化而变得稳健，使模型预测不可靠。"

## OODSelect算法

Salaudeen设计了一种名为OODSelect的算法来找出准确性在线原则被破坏的例子。该算法识别了数千个模型在训练数据和测试数据上的表现差异，揭示了问题子群体。

研究人员建议未来的工作采用OODSelect来突出评估目标和设计改进性能的方法。

*来源：[MIT News](https://news.mit.edu/2026/why-its-critical-to-move-beyond-overly-aggregated-machine-learning-metrics-0120)*
